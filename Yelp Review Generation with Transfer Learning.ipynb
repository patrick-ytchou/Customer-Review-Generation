{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8ccb65-42e1-42d4-a001-b7cca5aff50e",
   "metadata": {},
   "source": [
    "## Yelp Review Generation with Transfer Learning\n",
    "\n",
    "Text Generation is a popular subfield for Natural Language Processing that aims to generate text based on some **seed** text. This text can be done via RNN / LSTM to deal with sequence text data. However, this task cannot be easily done on normal computer given the humongous amount of data the model has to train on. \n",
    "\n",
    "Fortunately, new model training technologies have saved our lives. **Transfer Learning** is a learning technique in machine learning that focuses on transferring knowledge gained from training one problem to another similar task. For instance, we can use the neural network that are trained to classify cars to classify birds by changing later part of the model structure. \n",
    "\n",
    "Another wonderful news is that there are some research labs dedicating to open-sourced machine learning models. In this notebook, we will utilize the **GPT-2** model trained by **OpenAI**. GPT-2, **Generative pretrained transformer 2**, is a language model released in 2019 that are trained on 8 million web pages. It is a pretrained model with 1.5 billion parameters. \n",
    "\n",
    "Thanks to the open-sourced model, we can download the parameters directly through **Huggingface** API and fine-tuned via yelp review data. By doing this we can make use of the pretrained parameters in GPT-2 to best suit our review data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a423ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import string\n",
    "import gc\n",
    "import re\n",
    "from transformers import AutoTokenizer, TextDataset, DataCollatorForLanguageModeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bfea8e",
   "metadata": {},
   "source": [
    "### Prepare for Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c324bd2-7334-4941-a63c-f32dee981d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57562a5-1b89-4aef-8895-f0d920219ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_files(df, file_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    f = open(file_path, 'w')\n",
    "    text = '' \n",
    "    for sent in df.text:\n",
    "        summary = str(sent).strip().lower()\n",
    "        summary = re.sub(r\"\\s\", \" \", summary)\n",
    "        text += summary + \"  \"\n",
    "    f.write(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09c950b-173f-4881-93a0-994cf5498b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_input_text(filepath, tokenizer):\n",
    "    \"\"\"\n",
    "    Load and process input text for later modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filepath, index_col=0)\n",
    "    df['only_ascii'] =  df['text'].apply(lambda x: x.isascii())\n",
    "    df = df[df.only_ascii].reset_index(drop=True)\n",
    "    df = df[df['useful'] >= 30]\n",
    "    df = df.sample(1000)\n",
    "    \n",
    "    train, test = train_test_split(df, test_size = 0.3)\n",
    "    \n",
    "    # build text files\n",
    "    train = build_text_files(train, 'data/train_data.txt')\n",
    "    test = build_text_files(test, 'data/test_data.txt')\n",
    "    return train, test\n",
    "\n",
    "\n",
    "filepath = 'data/review.csv'\n",
    "train, test = load_and_process_input_text(filepath, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab58d26c-786e-4dee-89ca-aed13cdd2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transformer_dataset(train_path, test_path, tokenizer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train_dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = train_path,\n",
    "        block_size = 128\n",
    "    )\n",
    "    \n",
    "    test_dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = test_path,\n",
    "        block_size = 128\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer = tokenizer, mlm = False\n",
    "    )\n",
    "    \n",
    "    return train_dataset, test_dataset, data_collator\n",
    "\n",
    "train_path = 'data/train_data.txt'\n",
    "test_path = 'data/test_data.txt'\n",
    "train_dataset, test_dataset, data_collator = load_transformer_dataset(train_path, test_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc834021-11fa-4228-a5a4-744235424c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c81a8a-f068-4450-92e8-78c407a8b2b0",
   "metadata": {},
   "source": [
    "### Initialize Trainer with Training Arguments and GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baab99e3-ec63-45a4-8462-720e44aea4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "570fee3f-9e92-433c-a1d7-46c0d8b82ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50406624-7565-4000-b28f-77589e1130ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir = './gpt2',\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = 32, # batch size for training\n",
    "    per_device_eval_batch_size = 64, # batch size for evaluation\n",
    "    eval_steps = 400,\n",
    "    save_steps = 800, # after # of steps the model is saved\n",
    "    warmup_steps = 500,\n",
    "    prediction_loss_only = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = train_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e14c827-46f1-4f46-b413-a4f543326d14",
   "metadata": {},
   "source": [
    "### Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324262ba-0df3-4960-a94b-9cfbe5bb185a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 2:45:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=126, training_loss=4.071806408110119, metrics={'train_runtime': 10013.24, 'train_samples_per_second': 0.013, 'total_flos': 383903776309248, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54414768-3fe9-415c-8b62-e1fe1f321ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1948f05-8899-4a49-a886-4f67cc43453d",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce3f2a1-b3e1-4d94-aa4b-be4e6c550e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79628c55-4256-409f-87c7-0dee4f5d3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_review = pipeline('text-generation', model = './gpt2', tokenizer = 'gpt2', config = {'max_length': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eab08e81-c227-40bd-a2b4-0e45d1168e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"This is the best ice cream shop in the area and have a great selection. for those of you who are staying in the area with a friend or with new friends, we've got your back.   it's a great option for those looking\"}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_review('This is the best ice cream shop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "917e53fa-e590-47f6-b65f-2d231ac2e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"I love the beef noodle offered here. there's a huge chicken dish on each bun. it's really nice. i'll go back for a bowl. they didn't have any fresh bbq sauce in the bowl so i don't know\"}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_review('I love the beef noodle offered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "206081e9-f912-4c11-a44d-27078cb64b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'This is the worst steak in town,  but  we have never eaten a steak with this amount of meat!    my husband loves their homemade burgers and we are looking forward to coming back from this experience.  we ordered our own buffalo'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_review('This is the worst steak in town')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transfer-learning",
   "language": "python",
   "name": "transfer-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
